{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 단일 쓰레드, no batch, 종목 단위 트랜잭션\n",
    "\n",
    "import pymysql\n",
    "from openbb import obb\n",
    "\n",
    "# MySQL 연결 설정\n",
    "def connect_to_mysql():\n",
    "    connection = pymysql.connect(\n",
    "        host='host',\n",
    "        user='username',\n",
    "        password='password',\n",
    "        database='database'\n",
    "    )\n",
    "    return connection\n",
    "\n",
    "# Ticker 목록 가져오기\n",
    "def get_all_tickers(cursor):\n",
    "    sql = \"SELECT id, ticker FROM stock_info\"\n",
    "    cursor.execute(sql)\n",
    "    return cursor.fetchall()  # [(id, ticker), ...]\n",
    "\n",
    "# StockPrices 데이터 삽입 함수\n",
    "def insert_stock_price(cursor, stock_info_id, trade_date, open_price, close_price, high_price, low_price, volume):\n",
    "    sql = \"\"\"\n",
    "    INSERT INTO stock_prices (ticker_id, trade_date, open_price, close_price, high_price, low_price, volume)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "    ON DUPLICATE KEY UPDATE\n",
    "    open_price = VALUES(open_price),\n",
    "    close_price = VALUES(close_price),\n",
    "    high_price = VALUES(high_price),\n",
    "    low_price = VALUES(low_price),\n",
    "    volume = VALUES(volume)\n",
    "    \"\"\"\n",
    "    cursor.execute(sql, (stock_info_id, trade_date, open_price, close_price, high_price, low_price, volume))\n",
    "\n",
    "# OpenBB에서 특정 날짜의 가격 데이터 가져오기\n",
    "def fetch_historical_price(ticker, start_date, end_date):\n",
    "    df = obb.equity.price.historical(symbol=ticker, start_date=start_date, end_date=end_date)\n",
    "    return df.to_df()  # Pandas DataFrame 반환\n",
    "\n",
    "# Main 실행\n",
    "if __name__ == \"__main__\":\n",
    "    start_date = \"2024-12-01\"\n",
    "    end_date = \"2024-12-30\"\n",
    "\n",
    "    connection = None\n",
    "    try:\n",
    "        # MySQL 연결\n",
    "        connection = connect_to_mysql()\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Step 1: stock_info에서 모든 티커 가져오기\n",
    "        tickers = get_all_tickers(cursor)\n",
    "        print(f\"Found {len(tickers)} tickers in stock_info.\")\n",
    "\n",
    "        # Step 2: 각 티커에 대해 주가 데이터 가져오기 및 삽입\n",
    "        for stock_info_id, ticker in tickers:\n",
    "            try:\n",
    "                print(f\"Processing {ticker}...\")\n",
    "\n",
    "                # OpenBB를 이용해 주가 데이터 가져오기\n",
    "                historical_price_df = fetch_historical_price(ticker, start_date=start_date, end_date=end_date)\n",
    "                print(historical_price_df)\n",
    "\n",
    "                # DataFrame을 사용하여 데이터를 stock_prices 테이블에 삽입\n",
    "                for index, row in historical_price_df.iterrows():\n",
    "                    trade_date = index.strftime('%Y-%m-%d')  # 날짜 형식 변환\n",
    "                    insert_stock_price(\n",
    "                        cursor,\n",
    "                        stock_info_id,\n",
    "                        trade_date,\n",
    "                        row['open'],      # open_price\n",
    "                        row['close'],     # close_price\n",
    "                        row['high'],      # high_price\n",
    "                        row['low'],       # low_price\n",
    "                        row['volume']     # volume\n",
    "                    )\n",
    "\n",
    "                connection.commit() # 단건 커밋\n",
    "                print(f\"Price data for {ticker} inserted successfully.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {ticker}: {e}\")\n",
    "                connection.rollback()\n",
    "\n",
    "    except pymysql.MySQLError as e:\n",
    "        print(f\"MySQL Error: {e}\")\n",
    "    finally:\n",
    "        if connection:\n",
    "            connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. INSERT IGNORE(중복 데이터 무시)\n",
    "\n",
    "import pymysql\n",
    "import logging\n",
    "from openbb import obb\n",
    "\n",
    "# MySQL 연결 설정\n",
    "def connect_to_mysql():\n",
    "    connection = pymysql.connect(\n",
    "        host='host',\n",
    "        user='username',\n",
    "        password='password',\n",
    "        database='database'\n",
    "    )\n",
    "    return connection\n",
    "\n",
    "# Ticker 목록 가져오기\n",
    "def get_all_tickers(cursor):\n",
    "    sql = \"SELECT id, ticker FROM stock_info\"\n",
    "    cursor.execute(sql)\n",
    "    return cursor.fetchall()  # [(id, ticker), ...]\n",
    "\n",
    "# StockPrices 데이터 삽입 함수\n",
    "def insert_stock_price(cursor, stock_info_id, trade_date, open_price, close_price, high_price, low_price, volume):\n",
    "    sql = \"\"\"\n",
    "    INSERT IGNORE INTO stock_prices (ticker_id, trade_date, open_price, close_price, high_price, low_price, volume)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    cursor.execute(sql, (stock_info_id, trade_date, open_price, close_price, high_price, low_price, volume))\n",
    "\n",
    "# OpenBB에서 특정 날짜의 가격 데이터 가져오기\n",
    "def fetch_historical_price(ticker, start_date, end_date):\n",
    "    df = obb.equity.price.historical(symbol=ticker, start_date=start_date, end_date=end_date)\n",
    "    return df.to_df()  # Pandas DataFrame 반환\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(\n",
    "    filename=\"stock_price_update.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Main 실행\n",
    "if __name__ == \"__main__\":\n",
    "    start_date = \"2024-12-01\"\n",
    "    end_date = \"2024-12-03\"\n",
    "    batch_size = 5  # Batch 크기 설정\n",
    "\n",
    "    connection = None\n",
    "    try:\n",
    "        # MySQL 연결\n",
    "        connection = connect_to_mysql()\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Step 1: stock_info에서 모든 티커 가져오기\n",
    "        tickers = get_all_tickers(cursor)\n",
    "        logging.info(f\"Found {len(tickers)} tickers in stock_info.\")\n",
    "\n",
    "        # Step 2: Batch 처리로 각 티커에 대해 주가 데이터 가져오기 및 삽입\n",
    "        for batch_start in range(0, len(tickers), batch_size):\n",
    "            batch = tickers[batch_start:batch_start + batch_size]\n",
    "            logging.info(f\"Processing batch {batch_start // batch_size + 1}: {len(batch)} tickers\")\n",
    "\n",
    "            for stock_info_id, ticker in batch:\n",
    "                try:\n",
    "                    logging.info(f\"Processing {ticker}...\")\n",
    "\n",
    "                    # OpenBB를 이용해 주가 데이터 가져오기\n",
    "                    historical_price_df = fetch_historical_price(ticker, start_date=start_date, end_date=end_date)\n",
    "                    logging.info(f\"Fetched data for {ticker}. Rows: {len(historical_price_df)}\")\n",
    "\n",
    "                    # DataFrame을 사용하여 데이터를 stock_prices 테이블에 삽입\n",
    "                    for index, row in historical_price_df.iterrows():\n",
    "                        trade_date = index.strftime('%Y-%m-%d')  # 날짜 형식 변환\n",
    "\n",
    "                        # 데이터 삽입\n",
    "                        insert_stock_price(\n",
    "                            cursor,\n",
    "                            stock_info_id,\n",
    "                            trade_date,\n",
    "                            row['open'],      # open_price\n",
    "                            row['close'],     # close_price\n",
    "                            row['high'],      # high_price\n",
    "                            row['low'],       # low_price\n",
    "                            row['volume']     # volume\n",
    "                        )\n",
    "\n",
    "                    connection.commit()\n",
    "                    logging.info(f\"Price data for {ticker} inserted successfully.\")\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing {ticker}: {e}\")\n",
    "                    connection.rollback()  # 해당 티커만 롤백 처리\n",
    "\n",
    "    except pymysql.MySQLError as e:\n",
    "        logging.critical(f\"MySQL Error: {e}\")\n",
    "    finally:\n",
    "        if connection:\n",
    "            connection.close()\n",
    "        logging.info(\"Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. +) 비동기처리 통한 동시 작업 & executemany 통한 네트워크 오버헤드 감소\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import aiomysql\n",
    "import logging\n",
    "from openbb import obb\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# 로깅 설정 (파일에 저장)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # 로그 레벨 설정\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",  # 로그 포맷\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"stock_price_update.log\"),  # 로그를 파일에 저장\n",
    "        #logging.StreamHandler()  # 로그를 터미널에도 출력\n",
    "    ]\n",
    ")\n",
    "\n",
    "# MySQL 연결 설정\n",
    "async def connect_to_mysql():\n",
    "    return await aiomysql.connect(\n",
    "        host='host',\n",
    "        user='username',\n",
    "        password='password',\n",
    "        database='database',\n",
    "        minsize=1,\n",
    "        maxsize=40  # 동시 연결 최대 개수\n",
    "    )\n",
    "\n",
    "# Ticker 목록 가져오기\n",
    "async def get_all_tickers(cursor):\n",
    "    sql = \"SELECT id, ticker FROM stock_info\"\n",
    "    await cursor.execute(sql)\n",
    "    return await cursor.fetchall()  # [(id, ticker), ...]\n",
    "\n",
    "# Batch Insert 함수\n",
    "async def batch_insert_stock_prices(cursor, batch_data):\n",
    "    sql = \"\"\"\n",
    "    INSERT IGNORE INTO stock_prices (ticker_id, trade_date, open_price, close_price, high_price, low_price, volume)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    await cursor.executemany(sql, batch_data)\n",
    "\n",
    "# Ticker 데이터 처리\n",
    "async def process_ticker(pool, stock_info_id, ticker, start_date, end_date, semaphore):\n",
    "    async with semaphore:\n",
    "        async with pool.acquire() as conn:\n",
    "            async with conn.cursor() as cursor:\n",
    "                try:\n",
    "                    df = obb.equity.price.historical(symbol=ticker, start_date=start_date, end_date=end_date).to_df()\n",
    "                    df = df.dropna(subset=['open', 'close', 'high', 'low', 'volume'])\n",
    "                    df = df[(df['open'] > 0) & (df['close'] > 0) & (df['high'] > 0) & (df['low'] > 0)]\n",
    "\n",
    "                    batch_data = [\n",
    "                        (\n",
    "                            stock_info_id,\n",
    "                            index.strftime('%Y-%m-%d'),\n",
    "                            row['open'],\n",
    "                            row['close'],\n",
    "                            row['high'],\n",
    "                            row['low'],\n",
    "                            row['volume']\n",
    "                        )\n",
    "                        for index, row in df.iterrows()\n",
    "                    ]\n",
    "\n",
    "                    batch_size = 500  # 하나의 티커에 대한 데이터들을 배치 단위로 처리\n",
    "                    for i in range(0, len(batch_data), batch_size):\n",
    "                        batch = batch_data[i:i + batch_size]  # 배치 데이터 슬라이싱\n",
    "                        await batch_insert_stock_prices(cursor, batch)  # 배치 단위 삽입\n",
    "\n",
    "                    await conn.commit()  # 티커 단위 커밋\n",
    "                    logging.info(f\"Processed {ticker}: {len(batch_data)} rows inserted.\")\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing {ticker}: {e}\")\n",
    "                    await conn.rollback()\n",
    "\n",
    "# 메인 함수\n",
    "async def main():\n",
    "    start_date = \"2022-01-01\"\n",
    "    end_date = \"2022-12-31\"\n",
    "    pool = await aiomysql.create_pool(\n",
    "        host='host',\n",
    "        user='username',\n",
    "        password='password',\n",
    "        database='database',\n",
    "        minsize=1,\n",
    "        maxsize=40  # MySQL 연결 풀\n",
    "    )\n",
    "\n",
    "    semaphore = asyncio.Semaphore(60)  # 병렬 작업 제한\n",
    "\n",
    "    async with pool.acquire() as conn:\n",
    "        async with conn.cursor() as cursor:\n",
    "            tickers = await get_all_tickers(cursor)\n",
    "\n",
    "    tasks = [process_ticker(pool, stock_info_id, ticker, start_date, end_date, semaphore) for stock_info_id, ticker in tickers]\n",
    "    await asyncio.gather(*tasks)  # 비동기로 모든 티커 처리\n",
    "\n",
    "    pool.close()\n",
    "    await pool.wait_closed()\n",
    "\n",
    "# 실행\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. bulk insert \n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "from sqlalchemy import text, create_engine, event\n",
    "from openbb import obb\n",
    "import functools\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.FileHandler(\"query_log.log\")],\n",
    ")\n",
    "\n",
    "# [중요] INSERT 쿼리 횟수를 기록할 전역 변수\n",
    "insert_query_count = 0\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1) Decorator: 함수 실행 시간을 측정해서 로그를 남기는 데코레이터\n",
    "# ------------------------------------------------------------------------------\n",
    "def measure_time(func):\n",
    "    \"\"\"함수 실행 시간을 로깅하는 데코레이터.\"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        logging.info(f\"[TIMELOG] Function '{func.__name__}' took {elapsed_time:.4f} seconds.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2) MySQL 연결 엔진 생성. 이 때 이벤트 리스너 등록 (before/after_cursor_execute)\n",
    "# ------------------------------------------------------------------------------\n",
    "def create_engine_for_mysql():\n",
    "    \"\"\"MySQL 연결용 엔진 생성. 이벤트 리스너 등록\"\"\"\n",
    "    DATABASE_CONFIG = {\n",
    "        host='host',\n",
    "        user='username',\n",
    "        password='password',\n",
    "        database='database',\n",
    "    }\n",
    "    connection_string = (\n",
    "        f\"mysql+pymysql://{DATABASE_CONFIG['user']}:{DATABASE_CONFIG['password']}@\"\n",
    "        f\"{DATABASE_CONFIG['host']}/{DATABASE_CONFIG['database']}\"\n",
    "    )\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    # -- before_cursor_execute: 쿼리 실행 직전에 호출\n",
    "    @event.listens_for(engine, \"before_cursor_execute\", retval=True)\n",
    "    def before_cursor_execute(conn, cursor, statement, parameters, context, executemany):\n",
    "        \"\"\"\n",
    "        실제로 실행될 쿼리를 로그로 남기고, INSERT 쿼리 횟수를 전역 변수에 합산.\n",
    "        또한 시간을 재기 위해 context._query_start_time 을 설정.\n",
    "        \"\"\"\n",
    "        # 쿼리와 파라미터를 로그에 남긴다\n",
    "        logging.info(f\"[SQL START] statement: {statement}\")\n",
    "        logging.info(f\"[SQL START] parameters: {parameters}\")\n",
    "\n",
    "        # INSERT 쿼리 카운트 증가\n",
    "        global insert_query_count\n",
    "        if \"INSERT\" in statement.strip().upper():\n",
    "            insert_query_count += 1\n",
    "\n",
    "        # 쿼리 시작 시간 기록\n",
    "        context._query_start_time = time.time()\n",
    "\n",
    "        # retval=True 이므로, statement, parameters를 그대로 반환해야 한다\n",
    "        return statement, parameters\n",
    "\n",
    "    # -- after_cursor_execute: 쿼리 실행 직후에 호출\n",
    "    @event.listens_for(engine, \"after_cursor_execute\")\n",
    "    def after_cursor_execute(conn, cursor, statement, parameters, context, executemany):\n",
    "        \"\"\"\n",
    "        쿼리 실행 소요 시간을 측정하여 로그로 남긴다.\n",
    "        \"\"\"\n",
    "        elapsed = time.time() - context._query_start_time\n",
    "        logging.info(f\"[SQL END] Query took {elapsed:.4f} seconds.\")\n",
    "\n",
    "    return engine\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3) DB 유틸 함수들 (Decorator로 실행 시간 측정)\n",
    "# ------------------------------------------------------------------------------\n",
    "@measure_time\n",
    "def test_db_connection(engine):\n",
    "    \"\"\"DB 연결이 정상적으로 되는지 SELECT 1로 테스트\"\"\"\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(\"SELECT 1\"))\n",
    "            row = result.fetchone()\n",
    "            if row and row[0] == 1:\n",
    "                logging.info(\"DB connection success: SELECT 1 returned 1.\")\n",
    "            else:\n",
    "                logging.warning(f\"DB connection unexpected result: {row}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"DB connection failed: {e}\")\n",
    "        raise\n",
    "\n",
    "@measure_time\n",
    "def show_tables(engine):\n",
    "    \"\"\"DB 내 테이블 목록 확인\"\"\"\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(\"SHOW TABLES\"))\n",
    "            tables = [row[0] for row in result.fetchall()]\n",
    "            logging.info(f\"Tables in DB: {tables}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Could not retrieve table list: {e}\")\n",
    "\n",
    "@measure_time\n",
    "def count_inserted_rows(engine, table_name):\n",
    "    \"\"\"특정 테이블에 몇 건이 들어있는지 COUNT(*)로 확인\"\"\"\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(f\"SELECT COUNT(*) FROM {table_name}\"))\n",
    "            count_val = result.fetchone()[0]\n",
    "            logging.info(f\"'{table_name}' has {count_val} rows.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error counting rows from {table_name}: {e}\")\n",
    "\n",
    "@measure_time\n",
    "def get_all_tickers(engine):\n",
    "    \"\"\"stock_info 테이블에서 (id, ticker) 목록을 조회\"\"\"\n",
    "    query = \"SELECT id, ticker FROM stock_info\"\n",
    "    with engine.connect() as conn:\n",
    "        tickers_df = pd.read_sql(query, conn)\n",
    "    return tickers_df\n",
    "\n",
    "@measure_time\n",
    "def process_ticker(ticker_id, ticker, start_date, end_date):\n",
    "    \"\"\"OpenBB API로 시세 데이터 가져와 스키마 맞춰 전처리 후 DataFrame 반환\"\"\"\n",
    "    try:\n",
    "        df = obb.equity.price.historical(symbol=ticker, start_date=start_date, end_date=end_date).to_df()\n",
    "        df = df.dropna(subset=['open', 'close', 'high', 'low', 'volume'])\n",
    "        df = df[(df['open'] > 0) & (df['close'] > 0) & (df['high'] > 0) & (df['low'] > 0)]\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "\n",
    "        # 컬럼명 변경 및 추가\n",
    "        df['ticker_id'] = ticker_id\n",
    "        df['trade_date'] = df.index.strftime('%Y-%m-%d')\n",
    "        df = df.rename(columns={\n",
    "            'open': 'open_price',\n",
    "            'close': 'close_price',\n",
    "            'high': 'high_price',\n",
    "            'low': 'low_price',\n",
    "            'volume': 'volume'\n",
    "        })\n",
    "        return df[['ticker_id', 'trade_date', 'open_price', 'close_price', 'high_price', 'low_price', 'volume']]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {ticker}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "@measure_time\n",
    "def bulk_insert_with_pandas(engine, df, table_name, batch_size=1000):\n",
    "    \"\"\"Pandas to_sql로 배치 INSERT. 'multi' & chunksize=...\"\"\"\n",
    "    if df.empty:\n",
    "        logging.info(f\"No data to insert into table '{table_name}'.\")\n",
    "        return\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            df.to_sql(\n",
    "                name=table_name,\n",
    "                con=conn,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "                method=\"multi\",         # multi insert\n",
    "                chunksize=batch_size,\n",
    "            )\n",
    "        logging.info(f\"Finished inserting {len(df)} rows into '{table_name}'.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error inserting data into '{table_name}': {e}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4) 메인 함수\n",
    "# ------------------------------------------------------------------------------\n",
    "def main():\n",
    "    overall_start_time = time.time()\n",
    "\n",
    "    # 1. 날짜 범위 설정\n",
    "    start_date = \"2024-02-01\"\n",
    "    end_date   = \"2024-02-28\"\n",
    "\n",
    "    # 2. 엔진 생성 (+ 이벤트 리스너 등록)\n",
    "    engine = create_engine_for_mysql()\n",
    "\n",
    "    # 3. DB 연결 테스트\n",
    "    test_db_connection(engine)\n",
    "\n",
    "    # 4. DB 테이블 목록 확인\n",
    "    show_tables(engine)\n",
    "\n",
    "    # 5. 모든 티커의 데이터를 모으기\n",
    "    ticker_start = time.time()\n",
    "    tickers_df = get_all_tickers(engine)\n",
    "    all_data = []\n",
    "    for _, row in tickers_df.iterrows():\n",
    "        ticker_data = process_ticker(row[\"id\"], row[\"ticker\"], start_date, end_date)\n",
    "        all_data.append(ticker_data)\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    logging.info(f\"[DEBUG] final_df dtypes:\\n{final_df.dtypes}\")\n",
    "    logging.info(\"\\n\" + final_df.head(10).to_string())\n",
    "    logging.info(f\"[TIMELOG] All ticker processing took {time.time() - ticker_start:.4f} seconds.\")\n",
    "\n",
    "    # 6. bulk insert\n",
    "    insert_start = time.time()\n",
    "    bulk_insert_with_pandas(engine, final_df, \"stock_price\", batch_size=1000)\n",
    "    logging.info(f\"[TIMELOG] Bulk insert took {time.time() - insert_start:.4f} seconds.\")\n",
    "\n",
    "    # 7. 테이블 row 수 확인\n",
    "    count_inserted_rows(engine, \"stock_price\")\n",
    "\n",
    "    # 8. 실행 시간 계산\n",
    "    elapsed_time = time.time() - overall_start_time\n",
    "    logging.info(f\"[TIMELOG] Total execution time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # 9. INSERT 쿼리 개수 로그\n",
    "    global insert_query_count\n",
    "    logging.info(f\"[TIMELOG] Total INSERT queries executed: {insert_query_count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. bulk insert + 멀티스레드(concurrent.futures)\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "from sqlalchemy import text, create_engine, event\n",
    "from openbb import obb\n",
    "import functools\n",
    "import concurrent.futures  # 추가\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.FileHandler(\"query_log.log\")],\n",
    ")\n",
    "\n",
    "insert_query_count = 0\n",
    "\n",
    "def measure_time(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        logging.info(f\"[TIMELOG] Function '{func.__name__}' took {elapsed_time:.4f} seconds.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "def create_engine_for_mysql():\n",
    "    DATABASE_CONFIG = {\n",
    "        host='host',\n",
    "        user='username',\n",
    "        password='password',\n",
    "        database='database',\n",
    "    }\n",
    "    connection_string = (\n",
    "        f\"mysql+pymysql://{DATABASE_CONFIG['user']}:{DATABASE_CONFIG['password']}@\"\n",
    "        f\"{DATABASE_CONFIG['host']}/{DATABASE_CONFIG['database']}\"\n",
    "    )\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    @event.listens_for(engine, \"before_cursor_execute\", retval=True)\n",
    "    def before_cursor_execute(conn, cursor, statement, parameters, context, executemany):\n",
    "        logging.info(f\"[SQL START] statement: {statement}\")\n",
    "        logging.info(f\"[SQL START] parameters: {parameters}\")\n",
    "\n",
    "        global insert_query_count\n",
    "        if \"INSERT\" in statement.strip().upper():\n",
    "            insert_query_count += 1\n",
    "\n",
    "        context._query_start_time = time.time()\n",
    "        return statement, parameters\n",
    "\n",
    "    @event.listens_for(engine, \"after_cursor_execute\")\n",
    "    def after_cursor_execute(conn, cursor, statement, parameters, context, executemany):\n",
    "        elapsed = time.time() - context._query_start_time\n",
    "        logging.info(f\"[SQL END] Query took {elapsed:.4f} seconds.\")\n",
    "\n",
    "    return engine\n",
    "\n",
    "@measure_time\n",
    "def test_db_connection(engine):\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(\"SELECT 1\"))\n",
    "            row = result.fetchone()\n",
    "            if row and row[0] == 1:\n",
    "                logging.info(\"DB connection success: SELECT 1 returned 1.\")\n",
    "            else:\n",
    "                logging.warning(f\"DB connection unexpected result: {row}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"DB connection failed: {e}\")\n",
    "        raise\n",
    "\n",
    "@measure_time\n",
    "def show_tables(engine):\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(\"SHOW TABLES\"))\n",
    "            tables = [row[0] for row in result.fetchall()]\n",
    "            logging.info(f\"Tables in DB: {tables}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Could not retrieve table list: {e}\")\n",
    "\n",
    "@measure_time\n",
    "def count_inserted_rows(engine, table_name):\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(f\"SELECT COUNT(*) FROM {table_name}\"))\n",
    "            count_val = result.fetchone()[0]\n",
    "            logging.info(f\"'{table_name}' has {count_val} rows.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error counting rows from {table_name}: {e}\")\n",
    "\n",
    "@measure_time\n",
    "def get_all_tickers(engine):\n",
    "    query = \"SELECT id, ticker FROM stock_info\"\n",
    "    with engine.connect() as conn:\n",
    "        tickers_df = pd.read_sql(query, conn)\n",
    "    return tickers_df\n",
    "\n",
    "@measure_time\n",
    "def process_ticker(ticker_id, ticker, start_date, end_date):\n",
    "    \"\"\"단일 티커를 처리 (비동기로 병렬 호출 가능)\"\"\"\n",
    "    try:\n",
    "        df = obb.equity.price.historical(symbol=ticker, start_date=start_date, end_date=end_date).to_df()\n",
    "        df = df.dropna(subset=['open', 'close', 'high', 'low', 'volume'])\n",
    "        df = df[(df['open'] > 0) & (df['close'] > 0) & (df['high'] > 0) & (df['low'] > 0)]\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "\n",
    "        df['ticker_id'] = ticker_id\n",
    "        df['trade_date'] = df.index.strftime('%Y-%m-%d')\n",
    "        df = df.rename(columns={\n",
    "            'open': 'open_price',\n",
    "            'close': 'close_price',\n",
    "            'high': 'high_price',\n",
    "            'low': 'low_price',\n",
    "            'volume': 'volume'\n",
    "        })\n",
    "        return df[['ticker_id', 'trade_date', 'open_price', 'close_price', 'high_price', 'low_price', 'volume']]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {ticker}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "@measure_time\n",
    "def bulk_insert_with_pandas(engine, df, table_name, batch_size=50000):\n",
    "    if df.empty:\n",
    "        logging.info(f\"No data to insert into table '{table_name}'.\")\n",
    "        return\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            df.to_sql(\n",
    "                name=table_name,\n",
    "                con=conn,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "                method=\"multi\",\n",
    "                chunksize=batch_size,\n",
    "            )\n",
    "        logging.info(f\"Finished inserting {len(df)} rows into '{table_name}'.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error inserting data into '{table_name}': {e}\")\n",
    "\n",
    "def main():\n",
    "    overall_start_time = time.time()\n",
    "\n",
    "    start_date = \"2023-01-01\"\n",
    "    end_date   = \"2023-12-31\"\n",
    "\n",
    "    engine = create_engine_for_mysql()\n",
    "\n",
    "    test_db_connection(engine)\n",
    "    show_tables(engine)\n",
    "\n",
    "    tickers_df = get_all_tickers(engine)\n",
    "    logging.info(f\"Total tickers: {len(tickers_df)}\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # (1) 멀티스레드로 티커 데이터 가져오기\n",
    "    # ---------------------------\n",
    "    ticker_start_time = time.time()\n",
    "\n",
    "    all_data = []\n",
    "    # ThreadPoolExecutor의 기본 max_workers는 CPU 코어 수에 따라 결정되지만\n",
    "    # I/O가 큰 작업이라면 더 늘려도 됩니다 (ex: max_workers=10, 20).\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        future_to_ticker = {\n",
    "            executor.submit(process_ticker, row[\"id\"], row[\"ticker\"], start_date, end_date): row[\"ticker\"]\n",
    "            for _, row in tickers_df.iterrows()\n",
    "        }\n",
    "        # as_completed는 future가 완료되는 대로 순회\n",
    "        for future in concurrent.futures.as_completed(future_to_ticker):\n",
    "            ticker_symbol = future_to_ticker[future]\n",
    "            try:\n",
    "                result_df = future.result()\n",
    "                all_data.append(result_df)\n",
    "            except Exception as exc:\n",
    "                logging.error(f\"Ticker {ticker_symbol} generated an exception: {exc}\")\n",
    "\n",
    "    final_df = pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()\n",
    "    processing_time = time.time() - ticker_start_time\n",
    "    logging.info(f\"[TIMELOG] All ticker processing took {processing_time:.2f} seconds.\")\n",
    "    logging.info(f\"final_df shape: {final_df.shape}\")\n",
    "    logging.info(\"\\n\" + final_df.head(10).to_string())\n",
    "\n",
    "    # ---------------------------\n",
    "    # (2) DB Insert\n",
    "    # ---------------------------\n",
    "    insert_start_time = time.time()\n",
    "    bulk_insert_with_pandas(engine, final_df, \"stock_price\", batch_size=50000)\n",
    "    logging.info(f\"[TIMELOG] Bulk insert took {time.time() - insert_start_time:.2f} seconds.\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # (3) COUNT\n",
    "    # ---------------------------\n",
    "    count_inserted_rows(engine, \"stock_price\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # (4) 전체 소요 시간\n",
    "    # ---------------------------\n",
    "    elapsed_time = time.time() - overall_start_time\n",
    "    logging.info(f\"[TIMELOG] Total execution time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    global insert_query_count\n",
    "    logging.info(f\"[TIMELOG] Total INSERT queries executed: {insert_query_count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
